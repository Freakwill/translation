# 初学者的Keras：实现卷积神经网络

## 关于在Python中使用Keras实现简单卷积神经网络（CNN）的初学者友好指南。

2019年8月8日

![keras logo](https://victorzhou.com/static/c309c4c6a7bbdb43cf1f290786ce47ab/a8200/keras-logo.png)

[Keras](https://keras.io/) 是一个简单易用但功能强大的 Python 深度学习库。在这篇文章中，我们将用 Keras 构建一个简单的[卷积神经网络](https://victorzhou.com/blog/intro-to-cnns-part-1/)（CNN），并训练它来解实际问题。

这篇文章适用于**完全初学 Keras 的人**，但假设有 **CNNs 的基本背景知识**。我[对卷积神经网络的介绍](https://victorzhou.com/blog/intro-to-cnns-part-1/)涵盖了你在这篇文章中需要知道的一切（以及更多内容），如果需要，请先阅读。



我们现在就开始!

> 想要代码吗？[完整的源代码](https://victorzhou.com/blog/keras-cnn-tutorial/#the-full-code)在末尾。

## 问题：MNIST数字分类

我们将处理一个经典的[计算机视觉](https://victorzhou.com/tag/computer-vision/)入门问题：[MNIST](http://yann.lecun.com/exdb/mnist/) 手写数字分类。很简单：给定一个图像，将其分类为一个数字。



![Sample images from the MNIST dataset](https://victorzhou.com/static/16ddab2ee3bcd9e22d96f267e473a2f4/262c7/mnist-examples.png)

MNIST 数据集中的样本图像



MNIST 数据集中的每个图像都是 28x28，包含一个居中的灰度数字。我们的 CNN 将获取一个图像并输出 10 个可能的类中的一个（每个数字一个）。

## 1. 安装

我假设你已经有了一个基本的 Python 安装（可能是这样）。让我们先下载一些我们需要的包：

```bash
$ pip install keras tensorflow numpy mnist
```

> 注意：我们需要安装 `tensorflow` ，因为我们要在 [TensorFlow](https://www.tensorflow.org/) 后端上运行 Keras（即 TensorFlow 将装备 Keras ）。

现在你应该能够导入这些包并浏览 MNIST 数据集：

```python
import numpy as np
import mnist
import keras

# The first time you run this might be a bit slow, since the
# mnist package has to download and cache the data.
train_images = mnist.train_images()
train_labels = mnist.train_labels()

print(train_images.shape) # (60000, 28, 28)
print(train_labels.shape) # (60000,)
```

## 2. 准备数据

在开始之前，我们将把图像像素值从 [0，255] 规范化为 [-0.5，0.5] 以使网络更容易训练（使用较小的中心值通常会得到更好的结果）。我们还将把每个图像从（28，28）改为（28，28，1），因为 Keras 需要第三维度。

```python
import numpy as np
import mnist

train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Reshape the images.
train_images = np.expand_dims(train_images, axis=3)
test_images = np.expand_dims(test_images, axis=3)

print(train_images.shape) # (60000, 28, 28, 1)
print(test_images.shape)  # (10000, 28, 28, 1)
```

我们准备好开始构建我们的CNN了！

## 3. 构建模型

每个 Keras 模型要么使用表示层的线性堆栈的 [Sequential](https://keras.io/models/sequential/) 类构建，要么使用更可定制的功能 [Model](https://keras.io/models/model/) 类。我们将使用更简单的`Sequential` 模型，因为我们的CNN将是一个层的线性堆栈。

我们首先实例化一个 `Sequential` 模型：

```python
from keras.models import Sequential

# WIP
model = Sequential([
  # layers...
])
```

`Sequential` 构造函数接受一个 Keras [Layers](https://keras.io/layers/about-keras-layers/) 数组。我们将为 CNN 使用三种类型的层：**卷积层**、**最大池层**和 **Softmax 层**。

![img](https://victorzhou.com/media/cnn-post/cnn-dims-3.svg)

> 这是我们在我的 [CNN 简介](https://victorzhou.com/blog/intro-to-cnns-part-1/)中使用的 CNN 设置。如果你对这三种层的任何一种都不满意的话，请阅读这篇文章。

```python
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten

num_filters = 8
filter_size = 3
pool_size = 2

model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])
```

- `num_filters`, `filter_size` 和 `pool_size` 是设置 CNN 超参数的自解释变量。
- 任何 `Sequential` 模型中的第一层都必须指定输入 `input_shape`，因此我们在`Conv2D`上执行此操作。一旦指定了此输入形状，Keras 将自动推断后续层的输入形状。
- [Softmax](https://victorzhou.com/blog/softmax/) 输出层有 10 个节点，每个类一个。

## 4. 编译模型

在开始培训之前，我们需要配置训练过程。我们在编译过程中确定了3个关键因素：

- **优化器**。我们将坚持用一个非常好的默认设置：[Adam](https://arxiv.org/abs/1412.6980) 基于梯度的优化器。Keras 还有[许多其他优化器](https://keras.io/optimizers/)，你也可以查看。

- **损失函数**。因为我们使用的是 SoftMax 输出层，所以我们将使用交叉熵损失。Keras 区分 `binary_crossentropy` （2类）和 `categorical_crossentropy`（>2 类），因此我们将使用后者。[查看所有的 Keras 损失函数](https://keras.io/losses/).

- **度量**列表。因为这是一个分类问题，所以我们只会有关于准确度度量的 Keras 报告。

下面是编译的样子：

```python
model.compile(
  'adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
```

走起!

## 5. 训练模型

在 Keras 中训练模型实际上只包括调用 `fit()` 和指定一些参数。有[很多可能的参数](https://keras.io/models/sequential/#fit)，但我们只提供这些：

- **训练数据**（图像和标签），通常分别称为 X 和 Y。

- 训练的 **epoch 数**（整个数据集的迭代次数）。

- **验证数据**（或测试数据），在训练期间用于根据以前从未见过的数据定期测量网络性能。

有一件事我们必须小心：Keras 期望训练目标是 10 维向量，因为我们的 Softmax 输出层中有 10 个节点。现在，我们的**train_labels**和 `test_labels` 数组包含*表示每个图像的类的单个整数*：

```python
import mnist

train_labels = mnist.train_labels()
print(train_labels[0]) # 5
```

很方便，Keras 有一个实用的方法来解决这个确切的问题：[to_categorical](https://keras.io/utils/#to_categorical)。它将整数类数组转换为一个[独热](https://en.wikipedia.org/wiki/One-hot)向量数组。例如，2 将变为`[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]`（它是从零索引）。

这就是它的样子：

```python
from keras.utils import to_categorical

model.fit(
  train_images,
  to_categorical(train_labels),
  epochs=3,
  validation_data=(test_images, to_categorical(test_labels)),
)
```

我们现在可以把所有的东西放在一起训练我们的网络：

```python
import numpy as np
import mnist
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from keras.utils import to_categorical

train_images = mnist.train_images() 
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Reshape the images.
train_images = np.expand_dims(train_images, axis=3)
test_images = np.expand_dims(test_images, axis=3)

num_filters = 8
filter_size = 3
pool_size = 2

# Build the model.
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])

# Compile the model.
model.compile(
  'adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)

# Train the model.
model.fit(
  train_images,
  to_categorical(train_labels),
  epochs=3,
  validation_data=(test_images, to_categorical(test_labels)),
)
```

在完整 MNIST 数据集上运行该代码可以得到如下结果：

```text
Epoch 1
loss: 0.2433 - acc: 0.9276 - val_loss: 0.1176 - val_acc: 0.9634
Epoch 2
loss: 0.1184 - acc: 0.9648 - val_loss: 0.0936 - val_acc: 0.9721
Epoch 3
loss: 0.0930 - acc: 0.9721 - val_loss: 0.0778 - val_acc: 0.9744
```

我们用这个简单的 CNN 达到了 97.4% 的测试精度！

## 6. 使用模型

既然我们有了一个有效的、经过训练的模型，让我们来使用它。我们要做的第一件事是将它保存到磁盘上，这样我们就可以随时加载它：

```python
model.save_weights('cnn.h5')
```

通过重建模型并加载保存的权重，我们现在可以在任何需要的时候重新加载经过训练的模型：

```python
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten

num_filters = 8
filter_size = 3
pool_size = 2

# Build the model.
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])

# Load the model's saved weights.
model.load_weights('cnn.h5')
```

使用经过训练的模型进行预测很容易：我们将输入数组传递给 `predict()`，它返回一个输出数组。请记住，我们网络的输出是 10 个概率（因为 softmax），所以我们将使用 [np.argmax()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html) 将这些转换为实际数字。

```python
# Predict on the first 5 test images.
predictions = model.predict(test_images[:5])

# Print our model's predictions.
print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]

# Check our predictions against the ground truths.
print(test_labels[:5]) # [7, 2, 1, 0, 4]
```

## 8. 扩展

我们还可以做更多的实验并改进我们的网络 - 在这个[官方的 Keras MNIST CNN 例子](https://keras.io/examples/mnist_cnn/)中，他们在 12 个 epochs 后达到了99.25% 的测试精度。你可以对我们的 CNN 进行修改的一些例子包括：

### 网络深度

如果我们添加或删除 Convolutional 层会发生什么？这将如何影响训练和/或模型的最终性能？

```python
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  Conv2D(num_filters, filter_size),  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])
```

### Dropout

如果我们尝试添加通常用来防止过拟合的 [Dropout](https://keras.io/layers/core/#dropout) 层会发生什么？

```python
from keras.layers import Dropout
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Dropout(0.5),  Flatten(),
  Dense(10, activation='softmax'),
])
```

### 全连接层

如果我们在 Convolutional 输出和最终的 Softmax 层之间添加全连接层会发生什么？这是 CNNs 中用于[计算机视觉](https://victorzhou.com/tag/computer-vision/)的常见操作。

```python
from keras.layers import Dense
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(64, activation='relu'),  Dense(10, activation='softmax'),
])
```

### 卷积参数

如果我们使用 [Conv2D](https://keras.io/layers/convolutional/#conv2d) 参数会发生什么？例如：

```python
# These can be changed, too!
num_filters = 8
filter_size = 3

model = Sequential([
  # See https://keras.io/layers/convolutional/#conv2d for more info.
  Conv2D(
    num_filters,
    filter_size,
    input_shape=(28, 28, 1),
    strides=2,    padding='same',    activation='relu',  ),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])
```

## 结语

你已经用 Keras 实现了你的第一个 CNN！我们通过首个简单网络获得了 97.4% 的测试精度。我在下面再加一次完整的源代码供你参考。

你可能感兴趣的扩展阅读包括：

- 官方的 [Keras 入门](https://keras.io/#getting-started-30-seconds-to-keras)指南。
- 我关于[导出训练 CNNs 的反向传播算法](https://victorzhou.com/blog/intro-to-cnns-part-2/)的文章。
- [Keras 示例](https://github.com/keras-team/keras/tree/master/examples)集锦.
- 更多关于[神经网络](https://victorzhou.com/tag/neural-networks/)的文章.

谢谢你的阅读！完整的源代码如下。

## 完整代码

```python
# The full CNN code!
####################
import numpy as np
import mnist
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from keras.utils import to_categorical

train_images = mnist.train_images() 
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Reshape the images.
train_images = np.expand_dims(train_images, axis=3)
test_images = np.expand_dims(test_images, axis=3)

num_filters = 8
filter_size = 3
pool_size = 2

# Build the model.
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),
  MaxPooling2D(pool_size=pool_size),
  Flatten(),
  Dense(10, activation='softmax'),
])

# Compile the model.
model.compile(
  'adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)

# Train the model.
model.fit(
  train_images,
  to_categorical(train_labels),
  epochs=3,
  validation_data=(test_images, to_categorical(test_labels)),
)

# Save the model to disk.
model.save_weights('cnn.h5')

# Load the model from disk later using:
# model.load_weights('cnn.h5')

# Predict on the first 5 test images.
predictions = model.predict(test_images[:5])

# Print our model's predictions.
print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]

# Check our predictions against the ground truths.
print(test_labels[:5]) # [7, 2, 1, 0, 4]
```